{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-22 13:47:50,385 : INFO : Checking directories...\n",
      "2019-05-22 13:47:50,387 : INFO : Directories are set.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from itertools import groupby\n",
    "from io import BytesIO\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from models.unet import UNet\n",
    "import torch\n",
    "from data.data_loader import DataLoader\n",
    "from data.test_generator_for_submission import FGVC6SubmissionSetGenerator\n",
    "\n",
    "import random\n",
    "from utils.image_utils import get_mask_images\n",
    "\n",
    "FGVC6_DATA_SET_ROOT_PATH = '/Volumes/data-storag/data-sets/fgvc6-fashion/'\n",
    "MODEL_PATH = '{0}unet_parser_cloud.pt'.format(FGVC6_DATA_SET_ROOT_PATH)\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "WIDTH, HEIGHT = 512, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('{0}train.csv'.format(FGVC6_DATA_SET_ROOT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9f71901b6865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmask_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmask_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmask_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "sample = train_df.sample(1)\n",
    "img_name = sample.ImageId.values[0]\n",
    "img_width, img_height = sample.Width.values[0], sample.Height.values[0] \n",
    "img = cv2.imread('{0}train_images/{1}'.format(FGVC6_DATA_SET_ROOT_PATH, img_name))\n",
    "img = cv2.resize(img, (WIDTH, HEIGHT), interpolation=cv2.INTER_AREA)\n",
    "# HWC -> CHW\n",
    "img = img.transpose((2, 0, 1))\n",
    "img = np.asarray([img], dtype=np.float32) / 255\n",
    "\n",
    "X = torch.tensor(img, dtype=torch.float32).to(DEVICE)\n",
    "mask_pred = model(X)\n",
    "mask_pred = mask_pred.cpu().detach().numpy()\n",
    "mask_prob = np.argmax(mask_pred, axis=1)\n",
    "mask_prob = mask_prob.ravel(order='F')\n",
    "class_dict = submission_data_generator.run_length(mask_prob)\n",
    "\n",
    "mask_pred = np.swapaxes(mask_pred, 0, 1)\n",
    "mask_pred[mask_pred > .5] = 0.\n",
    "\n",
    "imgs = []\n",
    "for mask in mask_pred:\n",
    "    mat = np.reshape(mask, (WIDTH, HEIGHT))\n",
    "    # Creates PIL image\n",
    "    imgs.append(Image.fromarray(np.uint8(mat * 255) , 'L'))\n",
    "for im in imgs:\n",
    "    plt.figure()\n",
    "    plt.imshow(im, cmap='gray', vmin=0, vmax=255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
